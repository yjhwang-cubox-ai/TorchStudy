{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-08T08:25:48.758271Z",
     "start_time": "2024-08-08T08:25:44.297168Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from multiclass_functions import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transform_train = transforms.ToTensor()\n",
    "transform_test = transforms.ToTensor()"
   ],
   "id": "22a6d52151a1f72b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "train_DS = datasets.STL10(root='./data', split=\"train\", transform=transform_train, download=True)\n",
    "NoT = int(len(train_DS)*TRAIN_RATIO)\n",
    "NoV = len(train_DS) - NoT\n",
    "train_DS, val_DS = torch.utils.data.random_split(train_DS, [NoT, NoV])\n",
    "val_DS.transform = transform_test\n",
    "test_DS = datasets.STL10(root='./data', split=\"test\", transform=transform_test, download=True)\n",
    "\n",
    "train_DL = torch.utils.data.DataLoader(dataset=train_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_DL = torch.utils.data.DataLoader(dataset=val_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_DL = torch.utils.data.DataLoader(dataset=test_DS, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "id": "da69196796049daf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CNN_deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(nn.Conv2d(3,32,3, padding=1),\n",
    "                                        nn.BatchNorm2d(32),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(32,32,3, padding=1),\n",
    "                                        nn.BatchNorm2d(32),\n",
    "                                        nn.ReLU())\n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(nn.Conv2d(32,64,3, padding=1),\n",
    "                                        nn.BatchNorm2d(64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(64,64,3, padding=1),\n",
    "                                        nn.BatchNorm2d(64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(64,64,3, padding=1),\n",
    "                                        nn.BatchNorm2d(64),\n",
    "                                        nn.ReLU())\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv_block3 = nn.Sequential(nn.Conv2d(64,128,3, padding=1),\n",
    "                                        nn.BatchNorm2d(128),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(128,128,3, padding=1),\n",
    "                                        nn.BatchNorm2d(128),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(128,128,3, padding=1),\n",
    "                                        nn.BatchNorm2d(128),\n",
    "                                        nn.ReLU())\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(18432,512),\n",
    "                                nn.Linear(512, 10))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.Maxpool1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.Maxpool2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.Maxpool3(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "                \n",
    "        return x"
   ],
   "id": "c337f862e92a8212",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = CNN_deep()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "EPOCH = 100\n",
    "\n",
    "loss_hist = Train(model=model, train_DL=train_DL, criterion=criterion, optimizer=optimizer, EPOCH=EPOCH)"
   ],
   "id": "4b192c63f4e99c5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_model_path = \"CNN_V2.pth\"\n",
    "torch.save(model.state_dict(), save_model_path)"
   ],
   "id": "a7f7819b9b180d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_model_path = \"CNN_V2.pth\"\n",
    "load_model = CNN_deep().to(DEVICE)\n",
    "load_model.load_state_dict(torch.load(load_model_path))"
   ],
   "id": "d54b03245eb3e69a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Test(load_model, test_DL)",
   "id": "d3db90ff2684e9f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### parameters() vs. modules() vs. children() 그리고 instance 의 활용",
   "id": "571b7dd246f2f37a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(nn.Linear(2,3),\n",
    "                                 nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(3,4),\n",
    "                                 nn.ReLU())\n",
    "        self.fc_out = nn.Sequential(nn.Linear(4,1),\n",
    "                                    nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "print(model(torch.randn(2,2)).shape)\n",
    "print(model)"
   ],
   "id": "d28aeaaefb070234",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(model.parameters())",
   "id": "664978b998d3d976",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for transfer learning\n",
    "model = MLP()\n",
    "print([p for p in model.parameters() if p.requires_grad])"
   ],
   "id": "2916d9e760248c68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "print([p for p in model.parameters() if p.requires_grad])"
   ],
   "id": "c9cc6394dbbb99cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = MLP()\n",
    "# print([p for p in model.parameters() if p.requires_grad])\n",
    "\n",
    "# for p in model.parameters():\n",
    "#     p.requires_grad = False\n",
    "    # print(p)\n",
    "    # print(\"-\"*20)\n",
    "\n",
    "model.fc_out = nn.Linear(4,10)\n",
    "# print(\"-\"*20)\n",
    "# print(list(model.parameters()))\n",
    "# print([p for p in model.parameters() if p.requires_grad])\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "print(params)"
   ],
   "id": "e7c291ee287bc312",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "d698338a448cca3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(model.named_parameters())",
   "id": "a21f54da69e3ce32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(model.modules())",
   "id": "883f90bfad4e198f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d58516c00c6bbc8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ecd0c75752906e33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print([m for m in model.modules() if isinstance(m, nn.Linear)])\n",
    "print([m.weight for m in model.modules() if isinstance(m, nn.Linear)])\n",
    "print([m.weight.grad for m in model.modules() if isinstance(m, nn.Linear)])"
   ],
   "id": "8b64fa5c92368446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# weight initailization에 활용\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "print([m.weight for m in model.modules() if isinstance(m, nn.Linear)])"
   ],
   "id": "44628a28d0339dab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(model.children())",
   "id": "5bcc86141053fde5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print([m for m in model.children() if isinstance(m, nn.Linear)])",
   "id": "3a976b9c532b360b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print([m for m in model.modules() if isinstance(m, nn.Linear)])",
   "id": "47f18cf78c1b667f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.randn(2,2)\n",
    "\n",
    "y = list(model.children())[0](x)\n",
    "\n",
    "print(y)\n",
    "print(y.shape)"
   ],
   "id": "4d647450024fdd1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(*list(model.children())[:2])",
   "id": "ca930822308e3cda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(list(model.children())[:2])",
   "id": "753a82fd66ac1563",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ModuleList v.s. Sequential",
   "id": "de367924ec190391"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:25:48.793269Z",
     "start_time": "2024-08-08T08:25:48.759452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fc = nn.Linear(3,3)\n",
    "layer_list = [fc for _ in range(5)]"
   ],
   "id": "4085049bfa30bba1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:25:48.798330Z",
     "start_time": "2024-08-08T08:25:48.794031Z"
    }
   },
   "cell_type": "code",
   "source": "layer_list",
   "id": "5ae17a92b1d7ac7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=3, out_features=3, bias=True),\n",
       " Linear(in_features=3, out_features=3, bias=True),\n",
       " Linear(in_features=3, out_features=3, bias=True),\n",
       " Linear(in_features=3, out_features=3, bias=True),\n",
       " Linear(in_features=3, out_features=3, bias=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:29:27.236321Z",
     "start_time": "2024-08-08T08:29:27.233566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layers1 = nn.Sequential(*layer_list)\n",
    "layers2 = nn.ModuleList(layer_list)\n",
    "print(layers1)\n",
    "print(layers2)"
   ],
   "id": "f99dfc5e2af53072",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (3): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (4): Linear(in_features=3, out_features=3, bias=True)\n",
      ")\n",
      "ModuleList(\n",
      "  (0-4): 5 x Linear(in_features=3, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:31:25.482731Z",
     "start_time": "2024-08-08T08:31:25.478155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randn(2,3)\n",
    "y = layers1(x)\n",
    "print(y)\n",
    "\n",
    "for layer in layers2:\n",
    "    x = layer(x)\n",
    "print(x)    \n",
    "    \n",
    "for layer in layer_list:\n",
    "    x = layer(x)\n",
    "print(x)"
   ],
   "id": "d39e20c576c98577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1083, -0.2002,  0.0855],\n",
      "        [ 0.0893, -0.2087,  0.1074]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1083, -0.2002,  0.0855],\n",
      "        [ 0.0893, -0.2087,  0.1074]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:38:53.763311Z",
     "start_time": "2024-08-08T08:38:53.760843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 걍 리스트 쓰지 왜 nn.ModuleList 를 쓸까?\n",
    "class TestNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Module_List = [nn.Linear(3, 3), nn.Linear(3, 3)]\n",
    "        # self.Module_List = nn.ModuleList([nn.Linear(3, 3), nn.Linear(3, 3)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.Module_List:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x"
   ],
   "id": "4165d6307b84df17",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:38:54.000718Z",
     "start_time": "2024-08-08T08:38:53.925097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = TestNet()\n",
    "x = torch.randn(2,3)\n",
    "print(model(x))\n",
    "print(model) # 그냥 리스트로 하면 등록이 안돼있다!\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # 등록이 안되어있으면 parameter를 못 찾는다!"
   ],
   "id": "65fdf808b2da0ed8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0270, -0.7560, -0.3374],\n",
      "        [ 1.2017, -0.7936, -0.5331]], grad_fn=<AddmmBackward0>)\n",
      "TestNet()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(model(x))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(model) \u001B[38;5;66;03m# 그냥 리스트로 하면 등록이 안돼있다!\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/purestorage/project/yjhwang/opt/miniconda3/envs/vae/lib/python3.12/site-packages/torch/optim/adam.py:45\u001B[0m, in \u001B[0;36mAdam.__init__\u001B[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid weight_decay value: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mweight_decay\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     41\u001B[0m defaults \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(lr\u001B[38;5;241m=\u001B[39mlr, betas\u001B[38;5;241m=\u001B[39mbetas, eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[1;32m     42\u001B[0m                 weight_decay\u001B[38;5;241m=\u001B[39mweight_decay, amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[1;32m     43\u001B[0m                 maximize\u001B[38;5;241m=\u001B[39mmaximize, foreach\u001B[38;5;241m=\u001B[39mforeach, capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[1;32m     44\u001B[0m                 differentiable\u001B[38;5;241m=\u001B[39mdifferentiable, fused\u001B[38;5;241m=\u001B[39mfused)\n\u001B[0;32m---> 45\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefaults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fused:\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m differentiable:\n",
      "File \u001B[0;32m/purestorage/project/yjhwang/opt/miniconda3/envs/vae/lib/python3.12/site-packages/torch/optim/optimizer.py:279\u001B[0m, in \u001B[0;36mOptimizer.__init__\u001B[0;34m(self, params, defaults)\u001B[0m\n\u001B[1;32m    277\u001B[0m param_groups \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(params)\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(param_groups) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 279\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer got an empty parameter list\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(param_groups[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    281\u001B[0m     param_groups \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: param_groups}]\n",
      "\u001B[0;31mValueError\u001B[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:20:24.339144Z",
     "start_time": "2024-08-08T09:20:24.333422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그럼 nn.Sequential 쓰고 말지 왜 굳이 nn.ModuleList?\n",
    "class small_block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block_x = nn.Linear(1,1)\n",
    "        self.block_y = nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x = self.block_x(x)\n",
    "        y = self.block_y(y)\n",
    "        return x, y\n",
    "\n",
    "block = small_block()\n",
    "print(block)\n",
    "model = nn.Sequential(block, block)\n",
    "print(model)\n",
    "# model(torch.randn(1,1), torch.randn(1,1)) # error!\n",
    "# nn.Sequential 이 가지고 있는 forward 함수를 call 하기 때문에 입력을 두 개 넣으면 안된다!!\n",
    "\n",
    "model = nn.ModuleList([block, block])\n",
    "x = torch.randn(1)\n",
    "y = torch.randn(1)\n",
    "for block in model:\n",
    "    x,y = block(x,y)\n",
    "print(x,y)"
   ],
   "id": "dafce6594fd1c852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_block(\n",
      "  (block_x): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (block_y): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): small_block(\n",
      "    (block_x): Linear(in_features=1, out_features=1, bias=True)\n",
      "    (block_y): Linear(in_features=1, out_features=1, bias=True)\n",
      "  )\n",
      "  (1): small_block(\n",
      "    (block_x): Linear(in_features=1, out_features=1, bias=True)\n",
      "    (block_y): Linear(in_features=1, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.0106], grad_fn=<ViewBackward0>) tensor([-0.4860], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "61a6a04f6f72863f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
